{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripAdvisor restaurants info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tripadvisor.fr/Restaurants-g274772-Krakow_Lesser_Poland_Province_Southern_Poland.html#EATERY_OVERVIEW_BOX\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from the summary list of restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TripAdvisor URL to scroll through the restaurants list is built as follow:\n",
    "https://www.tripadvisor.com/RestaurantSearch-g1225481-oa15, where \n",
    "- g122548 is the id of the city\n",
    "- oa30 is the variable to scroll through the pages, by incrementing by 30 to go to the next page.\n",
    "\n",
    "Restaurants are sorted by descending Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "================================================\n",
    "Takes a city as an argument and scrape the\n",
    "summary data of each restaurants of the city\n",
    "through the TA restaurants display pages\n",
    "================================================\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from IPython.display import Filelink, Filelinks\n",
    "\n",
    "#Variables that will be used globally through the script\n",
    "url0 = 'https://www.tripadvisor.com'\n",
    "today = datetime.datetime.now()\n",
    "today_date = str(today.year) + '/' + str(today.month) + '/' + str(today.day)\n",
    "\n",
    "#Enable display of info messages\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scraper(city):\n",
    "    query = '/TypeAheadJson?action=API&startTime='+today_date+'&uiOrigin=GEOSCOPE&source=GEOSCOPE&interleaved=true&type=geo&neighborhood_geos=true&link_type=eat&details=true&max=12&injectNeighborhoods=true&query='+city\n",
    "    url = url0 + query\n",
    "    #Query the API ad get a JSON answer readable by Python as dictionnaries objects\n",
    "    api_response = requests.get(url).json()\n",
    "    geo = api_response['results'][0]['url']  #Get the URL from the results/1st element/Url key\n",
    "    restaurants_url = url0 + geo\n",
    "    logging.info(\"Scraping {} restaurants info\".format(city))\n",
    "    print(restaurants_url)\n",
    "\n",
    "    #Prepare the scrolling requests using a URL such as\n",
    "    #https://www.tripadvisor.com/RestaurantSearch-g1225481-oa15\n",
    "    scroll_url0= 'https://www.tripadvisor.com/RestaurantSearch-'\n",
    "    b = restaurants_url.find('-')\n",
    "    e = restaurants_url.find('-', b+1)\n",
    "    city_id = restaurants_url[b+1:e]\n",
    "    \n",
    "    #Initialize the lists of parameters to scrape and the dataframe containing all data\n",
    "    inc_page=0\n",
    "    resto_dict = {}\n",
    "    dataset = pd.DataFrame(resto_dict)\n",
    "    #columns=['Name', 'URL_TA', 'ID_TA', 'Rating', 'Ranking', 'Price Range', 'Cuisine Style', 'Number of Reviews', 'Reviews'])\n",
    "    \n",
    "    #Get the total number of pages\n",
    "    r = requests.get(scroll_url0+city_id,\n",
    "                     headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',},\n",
    "                     cookies= {\"SetCurrency\":\"EUR\"})\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    page_tag = soup.find_all(class_=\"pageNumbers\")[0] #tag that displays number of pages at bottom of webpage\n",
    "    a_tags = page_tag.find_all('a')  #last item of the returned list is the last page button\n",
    "    tot_pages=int(a_tags[-1].contents[0])  #integer from text content of the <a>\n",
    "    logging.info(\"{} pages to explore\".format(tot_pages))\n",
    "    \n",
    "    #Explore all the pages that display restaurants\n",
    "    for page_index in range (1, tot_pages+1):\n",
    "        \n",
    "        #URL of the current webpage\n",
    "        scroll_url = scroll_url0 + city_id + '-oa' + str(inc_page)\n",
    "        print(\"Scraping page nÂ°{}\".format(page_index))\n",
    "        print(scroll_url)\n",
    "\n",
    "        #Scrape HTML content of the current webpage using the library BeautifulSoup\n",
    "        r = requests.get(scroll_url,\n",
    "                 headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',},\n",
    "                cookies= {\"SetCurrency\":\"EUR\"})\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "\n",
    "        #Restaurants list starts with tag <div id=\"EATERY_SEARCH_RESULTS\">\n",
    "        data_bloc = soup.find_all(attrs={\"id\": \"EATERY_SEARCH_RESULTS\"}) #contains the data bloc in a list object\n",
    "        data_bloc = data_bloc[0]  #easier to manipulate\n",
    "\n",
    "    #First restaurant of page has a particular class attribute\n",
    "        if data_bloc.find_all(class_=\"listing rebrand listingIndex-1 first\") != []:\n",
    "            resto_soup = data_bloc.find_all(class_=\"listing rebrand listingIndex-1 first\")[0]\n",
    "        else:\n",
    "            resto_soup = data_bloc.find_all(class_=\"listing rebrand first\")[0]\n",
    "\n",
    "        #Get the url, id and name of restaurants\n",
    "        url_name_tag = resto_soup.find_all(class_=\"property_title\")[0] #tag containing the data\n",
    "        #Get restaurant URL\n",
    "        resto_dict['URL_TA'] = url_name_tag.get('href')\n",
    "        #Get the restaurant ID within its URL (-dxxxxxxx-Reviews)\n",
    "        b = url_name_tag.get('href').find('-d')\n",
    "        e= url_name_tag.get('href').find('-R')\n",
    "        resto_dict['ID_TA'] = url_name_tag.get('href')[b+1:e]\n",
    "        #Get names\n",
    "        resto_dict['Name'] = url_name_tag.contents[0][1:-1]\n",
    "\n",
    "        #Get the ranking of the restaurant\n",
    "        if resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\") != []:\n",
    "            ranking_tag = resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\")[0]\n",
    "            resto_dict['Ranking'] = ranking_tag.contents[0][1:-1]\n",
    "        else:\n",
    "            resto_dict['Ranking'] = np.nan #put a NaN instead\n",
    "\n",
    "        #Get the rating of the restaurant from <span> tags\n",
    "        if resto_soup.find_all('span') != []:\n",
    "            span_tags = resto_soup.find_all('span')\n",
    "            for tag in span_tags:\n",
    "                if tag.get('alt') is not None:\n",
    "                    resto_dict['Rating'] = tag.get('alt')\n",
    "        else:\n",
    "            resto_dict['Rating'] = np.nan\n",
    "\n",
    "        #Information from <div class=\"cuisines\">  \n",
    "        #!! some resaurants don't have pricerange nor cuisine styles, instead <div class=\"cuisine_margin\">\n",
    "        cuisines_tags = resto_soup.find_all(class_=\"cuisines\") #1 element of the list is 1 restaurant\n",
    "        if resto_soup.find_all(class_=\"cuisines\") != []:\n",
    "            for item in cuisines_tags:\n",
    "                #Get price range from <span class=\"item price\">\n",
    "                if item.find(class_=\"item price\") is not None:\n",
    "                    price_range = item.find(class_=\"item price\") #unique tag with price range\n",
    "                    resto_dict['Price Range'] = price_range.contents[0]\n",
    "                else:\n",
    "                     resto_dict['Price Range'] = np.nan\n",
    "                #Get cuisine styles from <span class=\"item cuisine\"> tags (several/restaurant)\n",
    "                if item.find_all(class_=\"item cuisine\") != []:\n",
    "                    cuisines = item.find_all(class_=\"item cuisine\")  # list of <a> tags with the cuisine style as text\n",
    "                    resto_dict['Cuisine Style'] = [tag.contents[0] for tag in cuisines]\n",
    "                else:\n",
    "                    resto_dict['Cuisine Style'] = np.nan\n",
    "\n",
    "        #Get number of reviews\n",
    "        if resto_soup.find_all(class_=\"reviewCount\") != []:\n",
    "            numb_tag = resto_soup.find_all(class_=\"reviewCount\")[0]\n",
    "            resto_dict['Number of Reviews'] = numb_tag.find('a').contents[0][1:-9]\n",
    "        else:\n",
    "            resto_dict['Number of Reviews'] = np.nan\n",
    "            \n",
    "        #Get 2 reviews (text+date) from <ul class=\"review_stubs review_snippets rebrand\"> and <li> tags within\n",
    "        ul_tags = resto_soup.find_all(class_=\"review_stubs review_snippets rebrand\")\n",
    "        if ul_tags != []:\n",
    "            for reviews_set in ul_tags:\n",
    "                rev_texts = reviews_set.find_all(dir=\"ltr\")\n",
    "                rev_dates = reviews_set.find_all(class_=\"date\")\n",
    "                resto_dict['Reviews'] = [[tag.find('a').contents[0] for tag in rev_texts], #text is in a <a> tag\n",
    "                                          [tag.contents[0] for tag in rev_dates]]\n",
    "        else:\n",
    "            resto_dict['Reviews'] = np.nan\n",
    "            \n",
    "        #Append the dataset\n",
    "        dataset = pd.concat([dataset, pd.DataFrame([resto_dict])])\n",
    "            \n",
    "    #For the rest of the list from 2 to 30:\n",
    "        try:\n",
    "            inc_rest = 0\n",
    "            for i in range (2, 31):\n",
    "                resto_dict = {}\n",
    "                resto_bloc_id = \"listing rebrand listingIndex-\" + str(i)\n",
    "                if data_bloc.find_all(class_=resto_bloc_id) != []:\n",
    "                    resto_soup = data_bloc.find_all(class_=resto_bloc_id)[0] #Bloc for one restaurant\n",
    "\n",
    "                    #Get the url, id and name of restaurants\n",
    "                    url_name_tag = resto_soup.find_all(class_=\"property_title\")[0] #tag containing the data\n",
    "                    #Get restaurant URL\n",
    "                    resto_dict['URL_TA'] = url_name_tag.get('href')\n",
    "                    #Get the restaurant ID within its URL (-dxxxxxxx-Reviews)\n",
    "                    b = url_name_tag.get('href').find('-d')\n",
    "                    e= url_name_tag.get('href').find('-R')\n",
    "                    resto_dict['ID_TA'] = url_name_tag.get('href')[b+1:e]\n",
    "                    #Get names\n",
    "                    resto_dict['Name'] = url_name_tag.contents[0][1:-1]\n",
    "\n",
    "                    #Get the ranking of the restaurant\n",
    "                    if resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\") != []:\n",
    "                        ranking_tag = resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\")[0]\n",
    "                        resto_dict['Ranking'] = ranking_tag.contents[0][1:-1]\n",
    "                    else:\n",
    "                        resto_dict['Ranking'] = np.nan\n",
    "\n",
    "                    #Get the rating of the restaurant from <span> tags\n",
    "                    span_tags = resto_soup.find_all('span')\n",
    "                    if resto_soup.find_all('span') != []:\n",
    "                        for tag in span_tags:\n",
    "                            if tag.get('alt') is not None:\n",
    "                                resto_dict['Rating'] = tag.get('alt')\n",
    "                    else:\n",
    "                        resto_dict['Rating'] = np.nan\n",
    "\n",
    "                    #Information from <div class=\"cuisines\">  \n",
    "                    #!! some resaurants don't have pricerange nor cuisine styles, instead <div class=\"cuisine_margin\">\n",
    "                    cuisines_tags = resto_soup.find_all(class_=\"cuisines\") #1 element of the list is 1 restaurant\n",
    "                    if resto_soup.find_all(class_=\"cuisines\") != []:\n",
    "                        for item in cuisines_tags:\n",
    "                            #Get price range from <span class=\"item price\">\n",
    "                            if item.find(class_=\"item price\") is not None:\n",
    "                                price_range = item.find(class_=\"item price\") #unique tag with price range\n",
    "                                resto_dict['Price Range'] = price_range.contents[0]\n",
    "                            else:\n",
    "                                resto_dict['Price Range'] = np.nan\n",
    "                            #Get cuisine styles from <span class=\"item cuisine\"> tags (several/restaurant)\n",
    "                            if item.find_all(class_=\"item cuisine\") != []:\n",
    "                                cuisines = item.find_all(class_=\"item cuisine\")  # list of <a> tags with the cuisine style as text\n",
    "                                resto_dict['Cuisine Style'] = [tag.contents[0] for tag in cuisines]\n",
    "                            else: \n",
    "                                resto_dict['Cuisine Style'] = np.nan\n",
    "\n",
    "                    #Get number of reviews\n",
    "                    if resto_soup.find_all(class_=\"reviewCount\") != []:\n",
    "                        numb_tag = resto_soup.find_all(class_=\"reviewCount\")[0]\n",
    "                        resto_dict['Number of Reviews'] = numb_tag.find('a').contents[0][1:-9]\n",
    "                    else:\n",
    "                        resto_dict['Number of Reviews'] = np.nan\n",
    "\n",
    "                    #Get 2 reviews (text+date) from <ul class=\"review_stubs review_snippets rebrand\"> and <li> tags within\n",
    "                    ul_tags = resto_soup.find_all(class_=\"review_stubs review_snippets rebrand\")\n",
    "                    if resto_soup.find_all(class_=\"review_stubs review_snippets rebrand\") != []:\n",
    "                        for reviews_set in ul_tags:\n",
    "                            rev_texts = reviews_set.find_all(dir=\"ltr\")\n",
    "                            rev_dates = reviews_set.find_all(class_=\"date\")\n",
    "                            resto_dict['Reviews'] = [[tag.find('a').contents[0] for tag in rev_texts], #text is in a <a> tag\n",
    "                                                  [tag.contents[0] for tag in rev_dates]]\n",
    "                    else:\n",
    "                        resto_dict['Reviews'] = np.nan\n",
    "                    \n",
    "                    #Append the dataset\n",
    "                    dataset = pd.concat([dataset, pd.DataFrame([resto_dict])])\n",
    "                        \n",
    "                else: #tag of restaurant is instead \"listing rebrand\"\n",
    "                    resto_soup = data_bloc.find_all(class_=\"listing rebrand\")[inc_rest]\n",
    "                    \n",
    "                    #Get the url, id and name of restaurants\n",
    "                    url_name_tag = resto_soup.find_all(class_=\"property_title\")[0] #tag containing the data\n",
    "                    #Get restaurant URL\n",
    "                    resto_dict['URL_TA'] = url_name_tag.get('href')\n",
    "                    #Get the restaurant ID within its URL (-dxxxxxxx-Reviews)\n",
    "                    b = url_name_tag.get('href').find('-d')\n",
    "                    e= url_name_tag.get('href').find('-R')\n",
    "                    resto_dict['ID_TA'] = url_name_tag.get('href')[b+1:e]\n",
    "                    #Get names\n",
    "                    resto_dict['Name'] = url_name_tag.contents[0][1:-1]\n",
    "\n",
    "                    #Get the ranking of the restaurant\n",
    "                    if resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\") != []:\n",
    "                        ranking_tag = resto_soup.find_all(class_=\"popIndex rebrand popIndexDefault\")[0]\n",
    "                        resto_dict['Ranking'] = ranking_tag.contents[0][1:-1]\n",
    "                    else:\n",
    "                        resto_dict['Ranking'] = np.nan\n",
    "\n",
    "                    #Get the rating of the restaurant from <span> tags\n",
    "                    span_tags = resto_soup.find_all('span')\n",
    "                    if resto_soup.find_all('span') != []:\n",
    "                        for tag in span_tags:\n",
    "                            if tag.get('alt') is not None:\n",
    "                                resto_dict['Rating'] = tag.get('alt')\n",
    "                    else:\n",
    "                        resto_dict['Rating'] = np.nan\n",
    "\n",
    "                    #Information from <div class=\"cuisines\">  \n",
    "                    #!! some resaurants don't have pricerange nor cuisine styles, instead <div class=\"cuisine_margin\">\n",
    "                    cuisines_tags = resto_soup.find_all(class_=\"cuisines\") #1 element of the list is 1 restaurant\n",
    "                    if resto_soup.find_all(class_=\"cuisines\") != []:\n",
    "                        for item in cuisines_tags:\n",
    "                            #Get price range from <span class=\"item price\">\n",
    "                            if item.find(class_=\"item price\") is not None:\n",
    "                                price_range = item.find(class_=\"item price\") #unique tag with price range\n",
    "                                resto_dict['Price Range'] = price_range.contents[0]\n",
    "                            else:\n",
    "                                resto_dict['Price Range'] = np.nan\n",
    "                            #Get cuisine styles from <span class=\"item cuisine\"> tags (several/restaurant)\n",
    "                            if item.find_all(class_=\"item cuisine\") != []:\n",
    "                                cuisines = item.find_all(class_=\"item cuisine\")  # list of <a> tags with the cuisine style as text\n",
    "                                resto_dict['Cuisine Style'] = [tag.contents[0] for tag in cuisines]\n",
    "                            else: \n",
    "                                resto_dict['Cuisine Style'] = np.nan\n",
    "\n",
    "                    #Get number of reviews\n",
    "                    if resto_soup.find_all(class_=\"reviewCount\") != []:\n",
    "                        numb_tag = resto_soup.find_all(class_=\"reviewCount\")[0]\n",
    "                        resto_dict['Number of Reviews'] = numb_tag.find('a').contents[0][1:-9]\n",
    "                    else:\n",
    "                        resto_dict['Number of Reviews'] = np.nan\n",
    "\n",
    "                    #Get 2 reviews (text+date) from <ul class=\"review_stubs review_snippets rebrand\"> and <li> tags within\n",
    "                    ul_tags = resto_soup.find_all(class_=\"review_stubs review_snippets rebrand\")\n",
    "                    if resto_soup.find_all(class_=\"review_stubs review_snippets rebrand\") != []:\n",
    "                        for reviews_set in ul_tags:\n",
    "                            rev_texts = reviews_set.find_all(dir=\"ltr\")\n",
    "                            rev_dates = reviews_set.find_all(class_=\"date\")\n",
    "                            resto_dict['Reviews'] = [[tag.find('a').contents[0] for tag in rev_texts], #text is in a <a> tag\n",
    "                                                  [tag.contents[0] for tag in rev_dates]]\n",
    "                    else:\n",
    "                        resto_dict['Reviews'] = np.nan\n",
    "                    \n",
    "                    #Append the dataset\n",
    "                    dataset = pd.concat([dataset, pd.DataFrame([resto_dict])])\n",
    "                    \n",
    "                    inc_rest += 1\n",
    "                \n",
    "            #Increment to next page to display the next 30 restaurants\n",
    "            inc_page += 30\n",
    "    \n",
    "        except IndexError:\n",
    "            logging.info(\"Last restaurant reached\")\n",
    "            break\n",
    "    \n",
    "    #Save dataframe as csv file\n",
    "    dataset.to_csv(city + '_TA_restaurants_raw.csv', sep=',', encoding=\"utf-8\")\n",
    "    print(\"File created in current directory: {}_TA_restaurants_raw.csv\".format(city))\n",
    "\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "scraper('Krakow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_capitals = ['Paris', 'London', 'Budapest', 'Madrid', 'Lisbon', 'Berlin', 'Rome', \n",
    "            'Athens', 'Vienna', 'Warsaw', 'Ljubljana', 'Dublin',\n",
    "                 'Bruxelles', 'Prague', 'Amsterdam', 'Luxembourg', 'Bratislava',\n",
    "                'Copenhagen', 'Oslo', 'Helsinki', 'Stockholm']\n",
    "#Paris London Budapest Madrid Lisbon Berlin already scraped\n",
    "for city in euro_capitals[6:]:\n",
    "    scraper(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to Exploratory notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = FileLink('2.Explorer.ipynb')\n",
    "print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
